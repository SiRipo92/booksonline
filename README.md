# Projet 2: Analyse de March√© avec Python

## Description

Ce projet vise √† d√©velopper une application Python qui automatise l'extraction, la transformation et le chargement (ETL) de donn√©es depuis le site [Books To Scrape](http://books.toscrape.com/). Le but est de r√©cup√©rer des informations produits, de les transformer en donn√©es exploitables et de les enregistrer dans des fichiers CSV. En parall√®le, une version beta est mise en place pour suivre les prix des livres au moment de l'ex√©cution.

## Objectifs d'Apprentissage

- **Programmation avec Python :** Automatiser la collecte de donn√©es depuis un site web.
- **Configuration d'un environnement de travail :** Mise en place d‚Äôun environnement virtuel et gestion des d√©pendances.
- **Utilisation de Git et GitHub :** Suivi des versions avec des commits r√©guliers et messages descriptifs.
- **D√©veloppement d'une pipeline ETL :** Extraction, transformation et chargement des donn√©es dans des CSV.

## Mission Principale

D√©velopper un scraper capable de :
- Extraire les informations produits depuis le site Books To Scrape.
- Transformer ces donn√©es en fichiers CSV.
- T√©l√©charger et enregistrer les images associ√©es aux produits.
- Mettre en place une version beta du syst√®me de surveillance des prix.

## Structure du Projet
```text
booksonline/
‚îú‚îÄ‚îÄ main.py                       # Point d'entr√©e du projet
‚îú‚îÄ‚îÄ requirements.txt              # D√©pendances Python √† installer
‚îú‚îÄ‚îÄ assets/                       # Contient les fichiers g√©n√©r√©s
‚îÇ   ‚îú‚îÄ‚îÄ csv/                      # CSV export√© contenant les donn√©es livres
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ book_data.csv
‚îÇ   ‚îî‚îÄ‚îÄ images/                   # Images t√©l√©charg√©es pour chaque livre
‚îú‚îÄ‚îÄ utils/                        # Package utilitaire contenant les fonctions du scraper
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ book_scraper.py          # Scrape les infos de chaque livre, √©crit le CSV, supprime les doublons
‚îÇ   ‚îî‚îÄ‚îÄ category_scraper.py      # Scrape les cat√©gories et les URL de chaque livre
```
### Comment les fichiers fonctionnent ensemble

#### üîÅ `main.py`
- Coordonne tout le processus ETL.
- Appelle les fonctions des modules `utils/` dans l'ordre logique :
  1. `generate_categories_list()` ‚Üí r√©cup√®re les cat√©gories du site.
  2. `scrape_category()` ‚Üí r√©cup√®re toutes les URLs de livres par cat√©gorie.
  3. `scrape_book()` ‚Üí r√©cup√®re les donn√©es de chaque livre (appel depuis `book_scraper.py`).
  4. `write_csv()` ‚Üí √©crit les donn√©es nettoy√©es dans un fichier CSV en supprimant les doublons.
  5. `download_book_images_from_csv()` ‚Üí t√©l√©charge les images selon les URL valides dans le CSV.

#### üß† `book_scraper.py`
- Fonction principale : `scrape_book(url)` :
  - Isole les donn√©es pertinentes (titre, prix, stock, etc.).
  - Nettoie et structure les r√©sultats dans un dictionnaire Python.
- `write_csv(book_info_list, file_path)` :
  - Supprime les doublons √† partir des `UPC`.
  - N'√©crit que les nouvelles entr√©es valides.
- `remove_csv_duplicate_rows(file_path)` :
  - Supprime toute r√©p√©tition ou ligne de type "header accidentel".

#### üìö `category_scraper.py`
- `generate_categories_list(base_url)` :
  - I/O: URL du site en entr√©e, dictionnaire `{nom_cat√©gorie: url}` en sortie.
- `scrape_category(category_url)` :
  - R√©cup√®re les pages d'une cat√©gorie en g√©rant la pagination.
  - En sortie :
    - le nombre total de livres,
    - le nombre total de pages,
    - une liste d‚ÄôURL de chaque livre.
- `extract_book_urls(page_url)` :
  - R√©cup√®re toutes les URL de livres list√©s dans une page de cat√©gorie.

### Avantages de l'organisation modulaire
- **Lisibilit√© am√©lior√©e** : chaque fichier a une mission claire (extraction, transformation, chargement).
- **Maintenance facilit√©e** : on peut modifier une fonction sans impacter le reste du syst√®me.
- **R√©utilisabilit√©** : fonctions comme `write_csv()` ou `scrape_book()` peuvent √™tre appel√©es ailleurs.
- **S√©paration des responsabilit√©s** : √©vite un fichier monolithique.


## Phases du Projet

### Phase 1 : Extraction d'une Page Produit

- **Objectif :**  
  Choisir une page produit sur Books To Scrape et extraire les informations suivantes :
  - `product_page_url`
  - `universal_product_code (upc)`
  - `title`
  - `price_including_tax`
  - `price_excluding_tax`
  - `number_available`
  - `product_description`
  - `category`
  - `review_rating`
  - `image_url`
- **Livrable :**  
  Un fichier CSV avec ces informations en en-t√™tes de colonnes.

### Phase 2 : Extraction des Donn√©es d'une Cat√©gorie

### Phase 1 : Extraction d'une Page Produit
- Extraire les donn√©es d√©taill√©es d'un livre donn√©.
- G√©n√©rer un dictionnaire des infos du livre.

### Phase 2 : Extraction d'une Cat√©gorie
- Scraper toutes les pages d'une cat√©gorie et leurs produits.
- G√©rer la pagination.

### Phase 3 : Extraction Globale
- Automatiser le scraping de toutes les cat√©gories du site.
- Agr√©ger les donn√©es dans un CSV.

### Phase 4 : T√©l√©chargement des Images
- Identifier et t√©l√©charger toutes les images depuis les URL extraites.
- V√©rifier qu‚Äôelles respectent les extensions autoris√©es (`.jpg`, `.jpeg`, `.png`, `.svg`, `.gif`, `.webp`).
- R√©essayer les t√©l√©chargements √©chou√©s avec un `timeout` et `retry`.

## Installation et Configuration

### Pr√©requis

- **Python 3.12**
- **Git** pour le contr√¥le de version

### Installation des D√©pendances

1. **Cr√©ez un environnement virtuel** (recommand√©) :
   ```bash
   python3 -m venv env
   ```
2. **Activez l'environnement virtuel**
   - Sur Windows
   ```
   .\env\Scripts\activate
   ```
   - Sur MacOs
   ```
   source env/bin/activate
3. **Installez les d√©pendances** depuis <code>requirements.txt</code>
```
pip install -r requirements.txt
```
    
*Note - ceci n'est pas inclus dans ce repository*

## Utilisation

Ex√©cuter le projet avec :
```bash
python3 main.py
```

Ce script :
- scrape toutes les cat√©gories,
- t√©l√©charge toutes les informations produit,
- nettoie les doublons,
- √©crit le CSV,
- t√©l√©charge les images si elles sont valides.

### Remarques
- **Surveillance en Temps R√©el:** Ce projet ne r√©alise pas une surveillance continue des prix, mais un relev√© des prix au moment de l'ex√©cution.
- **Fichiers √† Exclure:** Les fichiers g√©n√©r√©s (CSV, images, dossier de l'environnement virtuel dans le .gitignore)
- **Documentation:** Des commentaires dans le code et ce README fournissent une vue d'ensemble pour faciliter la compr√©hension et la maintenance du projet.

## Author
Sierra Ripoche - Junior web developer

## License

Ce projet est licenci√© sous la Licence Apache, Version 2.0.  
Voir le fichier [LICENSE.md](LICENSE.md) pour plus de d√©tails.